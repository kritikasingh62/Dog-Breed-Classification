{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "#Select 6 Convolution of size 3*3 , Input size of image is 32*32*3, it is a RGB image\n",
    "classifier.add(Conv2D(6, kernel_size=(5,5), activation='relu', input_shape=(64,64, 3)))\n",
    "#The output of the Convolution layer is 60*60*6 \n",
    "#Trainable parameters is (5 * 5 + 1) * 6= 156; \n",
    "#(5 * 5 = 25 unit parameters and one bias parameter per filter, a total of 6 filters)\n",
    "\n",
    "classifier.add( MaxPooling2D( pool_size=(3,3)))\n",
    "#The output of the Maximum Pooling layer is 30*30*6\n",
    "\n",
    "#The input matrix size of this layer is 30 * 30 * 6, the filter size used is 3 * 3, and the depth is 16. This layer does not use all 0 padding, and the step size is 1.\n",
    "# The output matrix size of this layer is 28 * 28 * 16.\n",
    "classifier.add(Conv2D(16, kernel_size=(3,3), activation='relu'))\n",
    "#The output of the Second Convolution layer is (30-3+1)=28\n",
    "classifier.add( MaxPooling2D( pool_size=(2,2)))\n",
    "#The output of the Maximum Pooling layer is 14*14*16\n",
    "classifier.add(Conv2D(16, kernel_size=(5,5), activation='relu'))\n",
    "#The output of the Second Convolution layer is (14-5+1)=10; 10*10*16\n",
    "classifier.add( MaxPooling2D( pool_size=(2,2)))\n",
    "#The output of the Maximum Pooling layer is 5*5*16\n",
    "# The input matrix size of this layer is 5 * 5 * 16. This layer is called a convolution layer in the LeNet-5 paper, but because the size of the filter is 5 * 5, #\n",
    "# So it is not different from the fully connected layer. If the nodes in the 5 * 5 * 16 matrix are pulled into a vector, then this layer is the same as the fully connected layer.\n",
    "# The number of output nodes in this layer is 120, with a total of 5 * 5 * 16 * 120 + 120 = 48120 parameters.\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(120, activation='relu'))\n",
    "\n",
    "# The number of input nodes in this layer is 120 and the number of output nodes is 84. The total parameter is 120 * 84 + 84 = 10164 (w + b)\n",
    "classifier.add(Dense(84, activation='relu'))\n",
    "classifier.add(Dense(120, activation='softmax'))\n",
    "classifier.compile(loss=keras.metrics.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17548 images belonging to 120 classes.\n",
      "Found 4322 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "# Part 2 - Fitting the CNN to the images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_data = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "\n",
    "test_data = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "\n",
    "training_set = train_data.flow_from_directory(r\"C:\\Users\\kriti\\OneDrive\\Desktop\\6th sem\\ML CS314b\\Projects\\train\",\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 128,\n",
    "                                                 class_mode = 'categorical')\n",
    "test_set = test_data.flow_from_directory(r\"C:\\Users\\kriti\\OneDrive\\Desktop\\6th sem\\ML CS314b\\Projects\\test\",\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 128,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "138/138 [==============================] - 533s 4s/step - loss: 4.3555 - accuracy: 0.0463 - val_loss: 4.1766 - val_accuracy: 0.0694\n",
      "Epoch 2/250\n",
      "138/138 [==============================] - 114s 827ms/step - loss: 4.3027 - accuracy: 0.0514 - val_loss: 4.1829 - val_accuracy: 0.0770\n",
      "Epoch 3/250\n",
      "138/138 [==============================] - 113s 816ms/step - loss: 4.2559 - accuracy: 0.0565 - val_loss: 4.0868 - val_accuracy: 0.0965\n",
      "Epoch 4/250\n",
      "138/138 [==============================] - 119s 862ms/step - loss: 4.2292 - accuracy: 0.0648 - val_loss: 4.2159 - val_accuracy: 0.0969\n",
      "Epoch 5/250\n",
      "138/138 [==============================] - 117s 845ms/step - loss: 4.1881 - accuracy: 0.0658 - val_loss: 4.0044 - val_accuracy: 0.1018\n",
      "Epoch 6/250\n",
      "138/138 [==============================] - 121s 875ms/step - loss: 4.1605 - accuracy: 0.0716 - val_loss: 3.9171 - val_accuracy: 0.0953\n",
      "Epoch 7/250\n",
      "138/138 [==============================] - 216s 2s/step - loss: 4.1294 - accuracy: 0.0745 - val_loss: 3.9347 - val_accuracy: 0.0944\n",
      "Epoch 8/250\n",
      "138/138 [==============================] - 187s 1s/step - loss: 4.0954 - accuracy: 0.0778 - val_loss: 3.8497 - val_accuracy: 0.1226\n",
      "Epoch 9/250\n",
      "138/138 [==============================] - 113s 821ms/step - loss: 4.0783 - accuracy: 0.0807 - val_loss: 4.1795 - val_accuracy: 0.1078\n",
      "Epoch 10/250\n",
      "138/138 [==============================] - 113s 819ms/step - loss: 4.0667 - accuracy: 0.0821 - val_loss: 3.9549 - val_accuracy: 0.1161\n",
      "Epoch 11/250\n",
      "138/138 [==============================] - 112s 813ms/step - loss: 4.0439 - accuracy: 0.0854 - val_loss: 4.0768 - val_accuracy: 0.1298\n",
      "Epoch 12/250\n",
      "138/138 [==============================] - 113s 820ms/step - loss: 4.0264 - accuracy: 0.0896 - val_loss: 3.6985 - val_accuracy: 0.1201\n",
      "Epoch 13/250\n",
      "138/138 [==============================] - 111s 805ms/step - loss: 4.0164 - accuracy: 0.0894 - val_loss: 3.7965 - val_accuracy: 0.1233\n",
      "Epoch 14/250\n",
      "138/138 [==============================] - 112s 813ms/step - loss: 3.9912 - accuracy: 0.0916 - val_loss: 4.0242 - val_accuracy: 0.1236\n",
      "Epoch 15/250\n",
      "138/138 [==============================] - 117s 851ms/step - loss: 3.9728 - accuracy: 0.0953 - val_loss: 3.7370 - val_accuracy: 0.1347\n",
      "Epoch 16/250\n",
      "138/138 [==============================] - 123s 894ms/step - loss: 3.9648 - accuracy: 0.0976 - val_loss: 3.8272 - val_accuracy: 0.1349\n",
      "Epoch 17/250\n",
      "138/138 [==============================] - 126s 911ms/step - loss: 3.9416 - accuracy: 0.1012 - val_loss: 3.9882 - val_accuracy: 0.1312\n",
      "Epoch 18/250\n",
      "138/138 [==============================] - 124s 900ms/step - loss: 3.9381 - accuracy: 0.1008 - val_loss: 3.8984 - val_accuracy: 0.1192\n",
      "Epoch 19/250\n",
      "138/138 [==============================] - 125s 905ms/step - loss: 3.9171 - accuracy: 0.1031 - val_loss: 3.8537 - val_accuracy: 0.1231\n",
      "Epoch 20/250\n",
      "138/138 [==============================] - 125s 909ms/step - loss: 3.9085 - accuracy: 0.1065 - val_loss: 3.8426 - val_accuracy: 0.1372\n",
      "Epoch 21/250\n",
      "138/138 [==============================] - 126s 911ms/step - loss: 3.8930 - accuracy: 0.1105 - val_loss: 3.8296 - val_accuracy: 0.1263\n",
      "Epoch 22/250\n",
      "138/138 [==============================] - 137s 995ms/step - loss: 3.8720 - accuracy: 0.1127 - val_loss: 3.6135 - val_accuracy: 0.1435\n",
      "Epoch 23/250\n",
      "138/138 [==============================] - 139s 1s/step - loss: 3.8683 - accuracy: 0.1125 - val_loss: 3.5975 - val_accuracy: 0.1485\n",
      "Epoch 24/250\n",
      "138/138 [==============================] - 129s 938ms/step - loss: 3.8499 - accuracy: 0.1146 - val_loss: 3.8230 - val_accuracy: 0.1522\n",
      "Epoch 25/250\n",
      "138/138 [==============================] - 128s 926ms/step - loss: 3.8381 - accuracy: 0.1164 - val_loss: 3.7681 - val_accuracy: 0.1400\n",
      "Epoch 26/250\n",
      "138/138 [==============================] - 133s 966ms/step - loss: 3.8351 - accuracy: 0.1192 - val_loss: 3.5110 - val_accuracy: 0.1409\n",
      "Epoch 27/250\n",
      "138/138 [==============================] - 143s 1s/step - loss: 3.8215 - accuracy: 0.1160 - val_loss: 3.6634 - val_accuracy: 0.1374\n",
      "Epoch 28/250\n",
      "138/138 [==============================] - 136s 984ms/step - loss: 3.7997 - accuracy: 0.1177 - val_loss: 3.6033 - val_accuracy: 0.1613\n",
      "Epoch 29/250\n",
      "138/138 [==============================] - 134s 973ms/step - loss: 3.7969 - accuracy: 0.1222 - val_loss: 3.5746 - val_accuracy: 0.1333\n",
      "Epoch 30/250\n",
      "138/138 [==============================] - 127s 919ms/step - loss: 3.7954 - accuracy: 0.1202 - val_loss: 3.8019 - val_accuracy: 0.1275\n",
      "Epoch 31/250\n",
      "138/138 [==============================] - 127s 918ms/step - loss: 3.7834 - accuracy: 0.1254 - val_loss: 3.4443 - val_accuracy: 0.1488\n",
      "Epoch 32/250\n",
      "138/138 [==============================] - 127s 917ms/step - loss: 3.7600 - accuracy: 0.1305 - val_loss: 3.6712 - val_accuracy: 0.1460\n",
      "Epoch 33/250\n",
      "138/138 [==============================] - 127s 923ms/step - loss: 3.7629 - accuracy: 0.1278 - val_loss: 3.7188 - val_accuracy: 0.1437\n",
      "Epoch 34/250\n",
      "138/138 [==============================] - 129s 934ms/step - loss: 3.7361 - accuracy: 0.1325 - val_loss: 3.7878 - val_accuracy: 0.1592\n",
      "Epoch 35/250\n",
      "138/138 [==============================] - 126s 910ms/step - loss: 3.7277 - accuracy: 0.1343 - val_loss: 3.8676 - val_accuracy: 0.1557\n",
      "Epoch 36/250\n",
      "138/138 [==============================] - 128s 930ms/step - loss: 3.7292 - accuracy: 0.1302 - val_loss: 3.9273 - val_accuracy: 0.1601\n",
      "Epoch 37/250\n",
      "138/138 [==============================] - 127s 917ms/step - loss: 3.7085 - accuracy: 0.1358 - val_loss: 3.6309 - val_accuracy: 0.1601\n",
      "Epoch 38/250\n",
      "138/138 [==============================] - 126s 912ms/step - loss: 3.6992 - accuracy: 0.1368 - val_loss: 3.8826 - val_accuracy: 0.1610\n",
      "Epoch 39/250\n",
      "138/138 [==============================] - 136s 988ms/step - loss: 3.6925 - accuracy: 0.1359 - val_loss: 3.7933 - val_accuracy: 0.1527\n",
      "Epoch 40/250\n",
      "138/138 [==============================] - 124s 896ms/step - loss: 3.6737 - accuracy: 0.1392 - val_loss: 3.7333 - val_accuracy: 0.1617\n",
      "Epoch 41/250\n",
      "138/138 [==============================] - 129s 937ms/step - loss: 3.6902 - accuracy: 0.1336 - val_loss: 3.6345 - val_accuracy: 0.1578\n",
      "Epoch 42/250\n",
      "138/138 [==============================] - 135s 977ms/step - loss: 3.6724 - accuracy: 0.1393 - val_loss: 3.9736 - val_accuracy: 0.1497\n",
      "Epoch 43/250\n",
      "138/138 [==============================] - 115s 835ms/step - loss: 3.6586 - accuracy: 0.1429 - val_loss: 3.8058 - val_accuracy: 0.1388\n",
      "Epoch 44/250\n",
      "138/138 [==============================] - 111s 805ms/step - loss: 3.6478 - accuracy: 0.1454 - val_loss: 3.5535 - val_accuracy: 0.1550\n",
      "Epoch 45/250\n",
      "138/138 [==============================] - 112s 810ms/step - loss: 3.6502 - accuracy: 0.1423 - val_loss: 3.9097 - val_accuracy: 0.1610\n",
      "Epoch 46/250\n",
      "138/138 [==============================] - 115s 832ms/step - loss: 3.6324 - accuracy: 0.1492 - val_loss: 3.6916 - val_accuracy: 0.1441\n",
      "Epoch 47/250\n",
      "138/138 [==============================] - 131s 951ms/step - loss: 3.6402 - accuracy: 0.1472 - val_loss: 3.6024 - val_accuracy: 0.1550\n",
      "Epoch 48/250\n",
      "138/138 [==============================] - 138s 998ms/step - loss: 3.6222 - accuracy: 0.1473 - val_loss: 3.5715 - val_accuracy: 0.1488\n",
      "Epoch 49/250\n",
      "138/138 [==============================] - 135s 978ms/step - loss: 3.6194 - accuracy: 0.1507 - val_loss: 3.6419 - val_accuracy: 0.1596\n",
      "Epoch 50/250\n",
      "138/138 [==============================] - 133s 961ms/step - loss: 3.6047 - accuracy: 0.1498 - val_loss: 3.5139 - val_accuracy: 0.1735\n",
      "Epoch 51/250\n",
      "138/138 [==============================] - 118s 853ms/step - loss: 3.5971 - accuracy: 0.1517 - val_loss: 3.6923 - val_accuracy: 0.1636\n",
      "Epoch 52/250\n",
      "138/138 [==============================] - 111s 803ms/step - loss: 3.5845 - accuracy: 0.1545 - val_loss: 3.8219 - val_accuracy: 0.1571\n",
      "Epoch 53/250\n",
      "138/138 [==============================] - 111s 805ms/step - loss: 3.5856 - accuracy: 0.1535 - val_loss: 3.7030 - val_accuracy: 0.1677\n",
      "Epoch 54/250\n",
      "138/138 [==============================] - 110s 799ms/step - loss: 3.5685 - accuracy: 0.1557 - val_loss: 3.7099 - val_accuracy: 0.1710\n",
      "Epoch 55/250\n",
      "138/138 [==============================] - 112s 808ms/step - loss: 3.5667 - accuracy: 0.1550 - val_loss: 3.6422 - val_accuracy: 0.1455\n",
      "Epoch 56/250\n",
      "138/138 [==============================] - 111s 804ms/step - loss: 3.5584 - accuracy: 0.1548 - val_loss: 3.6725 - val_accuracy: 0.1608\n",
      "Epoch 57/250\n",
      "138/138 [==============================] - 111s 804ms/step - loss: 3.5451 - accuracy: 0.1603 - val_loss: 3.6087 - val_accuracy: 0.1714\n",
      "Epoch 58/250\n",
      "138/138 [==============================] - 111s 806ms/step - loss: 3.5426 - accuracy: 0.1616 - val_loss: 3.9469 - val_accuracy: 0.1587\n",
      "Epoch 59/250\n",
      "138/138 [==============================] - 111s 805ms/step - loss: 3.5365 - accuracy: 0.1613 - val_loss: 3.7639 - val_accuracy: 0.1661\n",
      "Epoch 60/250\n",
      "138/138 [==============================] - 112s 815ms/step - loss: 3.5453 - accuracy: 0.1590 - val_loss: 3.8301 - val_accuracy: 0.1712\n",
      "Epoch 61/250\n",
      "138/138 [==============================] - 110s 799ms/step - loss: 3.5265 - accuracy: 0.1633 - val_loss: 3.6620 - val_accuracy: 0.1768\n",
      "Epoch 62/250\n",
      "138/138 [==============================] - 112s 814ms/step - loss: 3.5188 - accuracy: 0.1637 - val_loss: 3.4812 - val_accuracy: 0.1837\n",
      "Epoch 63/250\n",
      "138/138 [==============================] - 125s 908ms/step - loss: 3.5155 - accuracy: 0.1644 - val_loss: 3.5364 - val_accuracy: 0.1807\n",
      "Epoch 64/250\n",
      "138/138 [==============================] - 135s 977ms/step - loss: 3.5039 - accuracy: 0.1661 - val_loss: 3.4454 - val_accuracy: 0.1696\n",
      "Epoch 65/250\n",
      "138/138 [==============================] - 146s 1s/step - loss: 3.4934 - accuracy: 0.1642 - val_loss: 3.2120 - val_accuracy: 0.1770\n",
      "Epoch 66/250\n",
      "138/138 [==============================] - 141s 1s/step - loss: 3.4921 - accuracy: 0.1656 - val_loss: 3.5553 - val_accuracy: 0.1747\n",
      "Epoch 67/250\n",
      "138/138 [==============================] - 128s 926ms/step - loss: 3.4851 - accuracy: 0.1703 - val_loss: 3.3320 - val_accuracy: 0.1835\n",
      "Epoch 68/250\n",
      "138/138 [==============================] - 132s 957ms/step - loss: 3.4780 - accuracy: 0.1716 - val_loss: 3.8043 - val_accuracy: 0.1714\n",
      "Epoch 69/250\n",
      "138/138 [==============================] - 132s 958ms/step - loss: 3.4736 - accuracy: 0.1691 - val_loss: 3.1607 - val_accuracy: 0.1772\n",
      "Epoch 70/250\n",
      "138/138 [==============================] - 135s 977ms/step - loss: 3.4663 - accuracy: 0.1739 - val_loss: 3.6823 - val_accuracy: 0.1789\n",
      "Epoch 71/250\n",
      "138/138 [==============================] - 132s 957ms/step - loss: 3.4589 - accuracy: 0.1757 - val_loss: 3.5546 - val_accuracy: 0.1643\n",
      "Epoch 72/250\n",
      "138/138 [==============================] - 131s 950ms/step - loss: 3.4479 - accuracy: 0.1745 - val_loss: 3.6354 - val_accuracy: 0.1758\n",
      "Epoch 73/250\n",
      "138/138 [==============================] - 131s 949ms/step - loss: 3.4398 - accuracy: 0.1768 - val_loss: 3.7048 - val_accuracy: 0.1724\n",
      "Epoch 74/250\n",
      "138/138 [==============================] - 118s 855ms/step - loss: 3.4397 - accuracy: 0.1715 - val_loss: 3.8242 - val_accuracy: 0.1738\n",
      "Epoch 75/250\n",
      "138/138 [==============================] - 116s 842ms/step - loss: 3.4310 - accuracy: 0.1818 - val_loss: 3.8466 - val_accuracy: 0.1654\n",
      "Epoch 76/250\n",
      "138/138 [==============================] - 112s 812ms/step - loss: 3.4368 - accuracy: 0.1750 - val_loss: 3.5540 - val_accuracy: 0.1671\n",
      "Epoch 77/250\n",
      "138/138 [==============================] - 111s 806ms/step - loss: 3.4379 - accuracy: 0.1780 - val_loss: 3.8662 - val_accuracy: 0.1740\n",
      "Epoch 78/250\n",
      "138/138 [==============================] - 111s 805ms/step - loss: 3.4327 - accuracy: 0.1770 - val_loss: 3.5110 - val_accuracy: 0.1731\n",
      "Epoch 79/250\n",
      "138/138 [==============================] - 111s 804ms/step - loss: 3.3965 - accuracy: 0.1841 - val_loss: 3.6903 - val_accuracy: 0.1747\n",
      "Epoch 80/250\n",
      "138/138 [==============================] - 111s 805ms/step - loss: 3.4000 - accuracy: 0.1821 - val_loss: 3.7539 - val_accuracy: 0.1851\n",
      "Epoch 81/250\n",
      "138/138 [==============================] - 113s 816ms/step - loss: 3.3974 - accuracy: 0.1858 - val_loss: 3.5794 - val_accuracy: 0.1874\n",
      "Epoch 82/250\n",
      "138/138 [==============================] - 111s 803ms/step - loss: 3.4083 - accuracy: 0.1844 - val_loss: 3.5285 - val_accuracy: 0.1763\n",
      "Epoch 83/250\n",
      "138/138 [==============================] - 111s 806ms/step - loss: 3.4014 - accuracy: 0.1813 - val_loss: 3.6878 - val_accuracy: 0.1842\n",
      "Epoch 84/250\n",
      "138/138 [==============================] - 120s 872ms/step - loss: 3.3808 - accuracy: 0.1873 - val_loss: 3.5278 - val_accuracy: 0.1819\n",
      "Epoch 85/250\n",
      "138/138 [==============================] - 117s 851ms/step - loss: 3.3780 - accuracy: 0.1867 - val_loss: 3.3307 - val_accuracy: 0.1946\n",
      "Epoch 86/250\n",
      "138/138 [==============================] - 117s 849ms/step - loss: 3.3686 - accuracy: 0.1886 - val_loss: 3.2433 - val_accuracy: 0.1779\n",
      "Epoch 87/250\n",
      "138/138 [==============================] - 120s 873ms/step - loss: 3.3856 - accuracy: 0.1844 - val_loss: 3.4914 - val_accuracy: 0.1677\n",
      "Epoch 88/250\n",
      "138/138 [==============================] - 122s 887ms/step - loss: 3.3653 - accuracy: 0.1929 - val_loss: 3.7110 - val_accuracy: 0.1802\n",
      "Epoch 89/250\n",
      "138/138 [==============================] - 124s 899ms/step - loss: 3.3598 - accuracy: 0.1859 - val_loss: 3.4021 - val_accuracy: 0.1860\n",
      "Epoch 90/250\n",
      "138/138 [==============================] - 117s 845ms/step - loss: 3.3579 - accuracy: 0.1906 - val_loss: 3.3533 - val_accuracy: 0.1775\n",
      "Epoch 91/250\n",
      "138/138 [==============================] - 112s 811ms/step - loss: 3.3535 - accuracy: 0.1928 - val_loss: 3.2181 - val_accuracy: 0.1842\n",
      "Epoch 92/250\n",
      "138/138 [==============================] - 113s 816ms/step - loss: 3.3438 - accuracy: 0.1901 - val_loss: 3.6306 - val_accuracy: 0.1691\n",
      "Epoch 93/250\n",
      "138/138 [==============================] - 112s 814ms/step - loss: 3.3559 - accuracy: 0.1922 - val_loss: 3.6995 - val_accuracy: 0.1883\n",
      "Epoch 94/250\n",
      "138/138 [==============================] - 114s 824ms/step - loss: 3.3413 - accuracy: 0.1935 - val_loss: 3.9416 - val_accuracy: 0.1689\n",
      "Epoch 95/250\n",
      "138/138 [==============================] - 113s 819ms/step - loss: 3.3488 - accuracy: 0.1881 - val_loss: 3.5857 - val_accuracy: 0.2008\n",
      "Epoch 96/250\n",
      "138/138 [==============================] - 119s 862ms/step - loss: 3.3245 - accuracy: 0.1942 - val_loss: 3.4699 - val_accuracy: 0.1930\n",
      "Epoch 97/250\n",
      "138/138 [==============================] - 117s 850ms/step - loss: 3.3261 - accuracy: 0.1933 - val_loss: 3.2834 - val_accuracy: 0.1809\n",
      "Epoch 98/250\n",
      "138/138 [==============================] - 117s 851ms/step - loss: 3.3310 - accuracy: 0.1963 - val_loss: 3.6984 - val_accuracy: 0.1853\n",
      "Epoch 99/250\n",
      "138/138 [==============================] - 154s 1s/step - loss: 3.3099 - accuracy: 0.2011 - val_loss: 3.5653 - val_accuracy: 0.1763\n",
      "Epoch 100/250\n",
      "138/138 [==============================] - 173s 1s/step - loss: 3.3277 - accuracy: 0.1932 - val_loss: 3.5031 - val_accuracy: 0.1874\n",
      "Epoch 101/250\n",
      "138/138 [==============================] - 126s 910ms/step - loss: 3.3144 - accuracy: 0.2016 - val_loss: 3.8447 - val_accuracy: 0.1895\n",
      "Epoch 102/250\n",
      "138/138 [==============================] - 113s 822ms/step - loss: 3.3101 - accuracy: 0.1983 - val_loss: 3.4944 - val_accuracy: 0.1863\n",
      "Epoch 103/250\n",
      "138/138 [==============================] - 134s 972ms/step - loss: 3.3106 - accuracy: 0.1974 - val_loss: 3.6363 - val_accuracy: 0.1819\n",
      "Epoch 104/250\n",
      "138/138 [==============================] - 155s 1s/step - loss: 3.2946 - accuracy: 0.2015 - val_loss: 3.1658 - val_accuracy: 0.1826\n",
      "Epoch 105/250\n",
      "138/138 [==============================] - 184s 1s/step - loss: 3.2938 - accuracy: 0.2023 - val_loss: 3.5660 - val_accuracy: 0.1858\n",
      "Epoch 106/250\n",
      "138/138 [==============================] - 193s 1s/step - loss: 3.2865 - accuracy: 0.1980 - val_loss: 3.5917 - val_accuracy: 0.1964\n",
      "Epoch 107/250\n",
      "138/138 [==============================] - 188s 1s/step - loss: 3.2840 - accuracy: 0.2093 - val_loss: 3.6252 - val_accuracy: 0.1703\n",
      "Epoch 108/250\n",
      "138/138 [==============================] - 189s 1s/step - loss: 3.2903 - accuracy: 0.1989 - val_loss: 3.6823 - val_accuracy: 0.1798\n",
      "Epoch 109/250\n",
      "138/138 [==============================] - 212s 2s/step - loss: 3.2938 - accuracy: 0.2019 - val_loss: 3.6088 - val_accuracy: 0.1731\n",
      "Epoch 110/250\n",
      "138/138 [==============================] - 230s 2s/step - loss: 3.2851 - accuracy: 0.2011 - val_loss: 3.3056 - val_accuracy: 0.1976\n",
      "Epoch 111/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 202s 1s/step - loss: 3.2729 - accuracy: 0.2028 - val_loss: 3.4700 - val_accuracy: 0.2080\n",
      "Epoch 112/250\n",
      "138/138 [==============================] - 156s 1s/step - loss: 3.2702 - accuracy: 0.2049 - val_loss: 3.7625 - val_accuracy: 0.1849\n",
      "Epoch 113/250\n",
      "138/138 [==============================] - 142s 1s/step - loss: 3.2776 - accuracy: 0.2043 - val_loss: 3.8544 - val_accuracy: 0.1971\n",
      "Epoch 114/250\n",
      "138/138 [==============================] - 172s 1s/step - loss: 3.2689 - accuracy: 0.2024 - val_loss: 3.7017 - val_accuracy: 0.1890\n",
      "Epoch 115/250\n",
      "138/138 [==============================] - 123s 893ms/step - loss: 3.2494 - accuracy: 0.2125 - val_loss: 3.6813 - val_accuracy: 0.1814\n",
      "Epoch 116/250\n",
      "138/138 [==============================] - 124s 899ms/step - loss: 3.2641 - accuracy: 0.2089 - val_loss: 4.0030 - val_accuracy: 0.1863\n",
      "Epoch 117/250\n",
      "138/138 [==============================] - 132s 957ms/step - loss: 3.2735 - accuracy: 0.2022 - val_loss: 3.7919 - val_accuracy: 0.1851\n",
      "Epoch 118/250\n",
      "138/138 [==============================] - 120s 872ms/step - loss: 3.2411 - accuracy: 0.2093 - val_loss: 3.6631 - val_accuracy: 0.1927\n",
      "Epoch 119/250\n",
      "138/138 [==============================] - 133s 966ms/step - loss: 3.2487 - accuracy: 0.2075 - val_loss: 3.5467 - val_accuracy: 0.1950\n",
      "Epoch 120/250\n",
      "138/138 [==============================] - 138s 998ms/step - loss: 3.2318 - accuracy: 0.2089 - val_loss: 3.5091 - val_accuracy: 0.1999\n",
      "Epoch 121/250\n",
      "138/138 [==============================] - 196s 1s/step - loss: 3.2337 - accuracy: 0.2108 - val_loss: 3.4295 - val_accuracy: 0.1879\n",
      "Epoch 122/250\n",
      "138/138 [==============================] - 204s 1s/step - loss: 3.2325 - accuracy: 0.2103 - val_loss: 3.4530 - val_accuracy: 0.1853\n",
      "Epoch 123/250\n",
      "138/138 [==============================] - 211s 2s/step - loss: 3.2450 - accuracy: 0.2093 - val_loss: 3.6180 - val_accuracy: 0.1932\n",
      "Epoch 124/250\n",
      "138/138 [==============================] - 193s 1s/step - loss: 3.2377 - accuracy: 0.2090 - val_loss: 3.5047 - val_accuracy: 0.1793\n",
      "Epoch 125/250\n",
      "138/138 [==============================] - 198s 1s/step - loss: 3.2191 - accuracy: 0.2116 - val_loss: 3.6198 - val_accuracy: 0.1883\n",
      "Epoch 126/250\n",
      "138/138 [==============================] - 212s 2s/step - loss: 3.2319 - accuracy: 0.2118 - val_loss: 3.5727 - val_accuracy: 0.1821\n",
      "Epoch 127/250\n",
      "138/138 [==============================] - 212s 2s/step - loss: 3.2283 - accuracy: 0.2151 - val_loss: 3.4456 - val_accuracy: 0.1782\n",
      "Epoch 128/250\n",
      "138/138 [==============================] - 193s 1s/step - loss: 3.2453 - accuracy: 0.2112 - val_loss: 3.0526 - val_accuracy: 0.1927\n",
      "Epoch 129/250\n",
      "138/138 [==============================] - 124s 896ms/step - loss: 3.2105 - accuracy: 0.2154 - val_loss: 3.3300 - val_accuracy: 0.2001\n",
      "Epoch 130/250\n",
      "138/138 [==============================] - 124s 898ms/step - loss: 3.2193 - accuracy: 0.2120 - val_loss: 3.5274 - val_accuracy: 0.2013\n",
      "Epoch 131/250\n",
      "138/138 [==============================] - 120s 870ms/step - loss: 3.2032 - accuracy: 0.2185 - val_loss: 3.6275 - val_accuracy: 0.1895\n",
      "Epoch 132/250\n",
      "138/138 [==============================] - 128s 924ms/step - loss: 3.2174 - accuracy: 0.2098 - val_loss: 3.6552 - val_accuracy: 0.2045\n",
      "Epoch 133/250\n",
      "138/138 [==============================] - 127s 923ms/step - loss: 3.2004 - accuracy: 0.2199 - val_loss: 3.7645 - val_accuracy: 0.1779\n",
      "Epoch 134/250\n",
      "138/138 [==============================] - 130s 942ms/step - loss: 3.2052 - accuracy: 0.2167 - val_loss: 3.7676 - val_accuracy: 0.2015\n",
      "Epoch 135/250\n",
      "138/138 [==============================] - 132s 957ms/step - loss: 3.2056 - accuracy: 0.2124 - val_loss: 3.3541 - val_accuracy: 0.1925\n",
      "Epoch 136/250\n",
      "138/138 [==============================] - 132s 957ms/step - loss: 3.2071 - accuracy: 0.2132 - val_loss: 3.1098 - val_accuracy: 0.1983\n",
      "Epoch 137/250\n",
      "138/138 [==============================] - 134s 972ms/step - loss: 3.1826 - accuracy: 0.2206 - val_loss: 3.6031 - val_accuracy: 0.2011\n",
      "Epoch 138/250\n",
      "138/138 [==============================] - 134s 969ms/step - loss: 3.1813 - accuracy: 0.2169 - val_loss: 3.7021 - val_accuracy: 0.2008\n",
      "Epoch 139/250\n",
      "138/138 [==============================] - 140s 1s/step - loss: 3.1664 - accuracy: 0.2197 - val_loss: 3.2650 - val_accuracy: 0.1964\n",
      "Epoch 140/250\n",
      "138/138 [==============================] - 133s 963ms/step - loss: 3.1858 - accuracy: 0.2176 - val_loss: 3.4081 - val_accuracy: 0.1932\n",
      "Epoch 141/250\n",
      "138/138 [==============================] - 133s 963ms/step - loss: 3.1789 - accuracy: 0.2230 - val_loss: 3.5157 - val_accuracy: 0.1930\n",
      "Epoch 142/250\n",
      "138/138 [==============================] - 131s 947ms/step - loss: 3.1849 - accuracy: 0.2193 - val_loss: 3.6181 - val_accuracy: 0.1863\n",
      "Epoch 143/250\n",
      "138/138 [==============================] - 133s 961ms/step - loss: 3.1780 - accuracy: 0.2187 - val_loss: 3.3651 - val_accuracy: 0.2031\n",
      "Epoch 144/250\n",
      "138/138 [==============================] - 133s 966ms/step - loss: 3.1803 - accuracy: 0.2233 - val_loss: 3.4634 - val_accuracy: 0.1978\n",
      "Epoch 145/250\n",
      "138/138 [==============================] - 134s 973ms/step - loss: 3.1964 - accuracy: 0.2164 - val_loss: 3.5474 - val_accuracy: 0.1990\n",
      "Epoch 146/250\n",
      "138/138 [==============================] - 134s 972ms/step - loss: 3.1738 - accuracy: 0.2228 - val_loss: 3.6473 - val_accuracy: 0.2059\n",
      "Epoch 147/250\n",
      "138/138 [==============================] - 140s 1s/step - loss: 3.1557 - accuracy: 0.2229 - val_loss: 3.7402 - val_accuracy: 0.1856\n",
      "Epoch 148/250\n",
      "138/138 [==============================] - 141s 1s/step - loss: 3.1762 - accuracy: 0.2198 - val_loss: 3.6056 - val_accuracy: 0.1981\n",
      "Epoch 149/250\n",
      "138/138 [==============================] - 141s 1s/step - loss: 3.1677 - accuracy: 0.2252 - val_loss: 3.4746 - val_accuracy: 0.2149\n",
      "Epoch 150/250\n",
      "138/138 [==============================] - 148s 1s/step - loss: 3.1618 - accuracy: 0.2238 - val_loss: 3.6069 - val_accuracy: 0.1863\n",
      "Epoch 151/250\n",
      "138/138 [==============================] - 143s 1s/step - loss: 3.1754 - accuracy: 0.2228 - val_loss: 3.3280 - val_accuracy: 0.1957\n",
      "Epoch 152/250\n",
      "138/138 [==============================] - 130s 941ms/step - loss: 3.1539 - accuracy: 0.2237 - val_loss: 3.5800 - val_accuracy: 0.1997\n",
      "Epoch 153/250\n",
      "138/138 [==============================] - 138s 1s/step - loss: 3.1381 - accuracy: 0.2298 - val_loss: 3.3871 - val_accuracy: 0.2041\n",
      "Epoch 154/250\n",
      "138/138 [==============================] - 131s 950ms/step - loss: 3.1532 - accuracy: 0.2248 - val_loss: 3.3761 - val_accuracy: 0.1999\n",
      "Epoch 155/250\n",
      "138/138 [==============================] - 137s 993ms/step - loss: 3.1430 - accuracy: 0.2277 - val_loss: 3.7395 - val_accuracy: 0.1983\n",
      "Epoch 156/250\n",
      "138/138 [==============================] - 137s 993ms/step - loss: 3.1547 - accuracy: 0.2249 - val_loss: 3.5026 - val_accuracy: 0.1983\n",
      "Epoch 157/250\n",
      "138/138 [==============================] - 143s 1s/step - loss: 3.1616 - accuracy: 0.2249 - val_loss: 3.8080 - val_accuracy: 0.1927\n",
      "Epoch 158/250\n",
      "138/138 [==============================] - 137s 995ms/step - loss: 3.1445 - accuracy: 0.2234 - val_loss: 3.1497 - val_accuracy: 0.2078\n",
      "Epoch 159/250\n",
      "138/138 [==============================] - 140s 1s/step - loss: 3.1383 - accuracy: 0.2254 - val_loss: 3.4325 - val_accuracy: 0.1944\n",
      "Epoch 160/250\n",
      "138/138 [==============================] - 136s 984ms/step - loss: 3.1311 - accuracy: 0.2278 - val_loss: 3.2364 - val_accuracy: 0.2022\n",
      "Epoch 161/250\n",
      "138/138 [==============================] - 135s 981ms/step - loss: 3.1327 - accuracy: 0.2279 - val_loss: 3.6170 - val_accuracy: 0.2004\n",
      "Epoch 162/250\n",
      "138/138 [==============================] - 138s 999ms/step - loss: 3.1577 - accuracy: 0.2248 - val_loss: 3.7466 - val_accuracy: 0.1976\n",
      "Epoch 163/250\n",
      "138/138 [==============================] - 137s 990ms/step - loss: 3.1264 - accuracy: 0.2270 - val_loss: 3.6402 - val_accuracy: 0.1937\n",
      "Epoch 164/250\n",
      "138/138 [==============================] - 137s 994ms/step - loss: 3.1420 - accuracy: 0.2256 - val_loss: 3.8923 - val_accuracy: 0.2066\n",
      "Epoch 165/250\n",
      "138/138 [==============================] - 124s 898ms/step - loss: 3.1332 - accuracy: 0.2277 - val_loss: 3.3718 - val_accuracy: 0.2087\n",
      "Epoch 166/250\n",
      "138/138 [==============================] - 116s 838ms/step - loss: 3.1329 - accuracy: 0.2315 - val_loss: 3.7273 - val_accuracy: 0.1988\n",
      "Epoch 167/250\n",
      "138/138 [==============================] - 112s 811ms/step - loss: 3.1221 - accuracy: 0.2301 - val_loss: 3.4520 - val_accuracy: 0.2055\n",
      "Epoch 168/250\n",
      "138/138 [==============================] - 111s 802ms/step - loss: 3.1370 - accuracy: 0.2317 - val_loss: 3.3028 - val_accuracy: 0.1950\n",
      "Epoch 169/250\n",
      "138/138 [==============================] - 111s 807ms/step - loss: 3.1075 - accuracy: 0.2317 - val_loss: 3.6734 - val_accuracy: 0.2029\n",
      "Epoch 170/250\n",
      "138/138 [==============================] - 109s 792ms/step - loss: 3.1081 - accuracy: 0.2311 - val_loss: 3.6130 - val_accuracy: 0.2045\n",
      "Epoch 171/250\n",
      "138/138 [==============================] - 110s 794ms/step - loss: 3.1197 - accuracy: 0.2347 - val_loss: 3.8333 - val_accuracy: 0.2013\n",
      "Epoch 172/250\n",
      "138/138 [==============================] - 109s 788ms/step - loss: 3.1152 - accuracy: 0.2339 - val_loss: 3.6052 - val_accuracy: 0.1911\n",
      "Epoch 173/250\n",
      "120/138 [=========================>....] - ETA: 27:12 - loss: 3.0896 - accuracy: 0.2390"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda2\\lib\\site-packages\\keras\\utils\\data_utils.py:616: UserWarning: The input 93 could not be retrieved. It could be because a worker has died.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/138 [=========================>....] - ETA: 48:24 - loss: 3.0915 - accuracy: 0.2387"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda2\\lib\\site-packages\\keras\\utils\\data_utils.py:616: UserWarning: The input 7 could not be retrieved. It could be because a worker has died.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 22614s 164s/step - loss: 3.1011 - accuracy: 0.2373 - val_loss: 3.5761 - val_accuracy: 0.2001\n",
      "Epoch 174/250\n",
      "138/138 [==============================] - 1011s 7s/step - loss: 3.0984 - accuracy: 0.2342 - val_loss: 3.8900 - val_accuracy: 0.1872\n",
      "Epoch 175/250\n",
      "138/138 [==============================] - 175s 1s/step - loss: 3.1154 - accuracy: 0.2330 - val_loss: 3.6874 - val_accuracy: 0.1925\n",
      "Epoch 176/250\n",
      "138/138 [==============================] - 169s 1s/step - loss: 3.1250 - accuracy: 0.2299 - val_loss: 3.5998 - val_accuracy: 0.1978\n",
      "Epoch 177/250\n",
      "138/138 [==============================] - 118s 852ms/step - loss: 3.1051 - accuracy: 0.2365 - val_loss: 3.1406 - val_accuracy: 0.2045\n",
      "Epoch 178/250\n",
      "138/138 [==============================] - 122s 884ms/step - loss: 3.1214 - accuracy: 0.2305 - val_loss: 3.2061 - val_accuracy: 0.1960\n",
      "Epoch 179/250\n",
      "138/138 [==============================] - 122s 881ms/step - loss: 3.0993 - accuracy: 0.2323 - val_loss: 4.1072 - val_accuracy: 0.1953\n",
      "Epoch 180/250\n",
      "138/138 [==============================] - 119s 865ms/step - loss: 3.1112 - accuracy: 0.2309 - val_loss: 3.6120 - val_accuracy: 0.1856\n",
      "Epoch 181/250\n",
      "138/138 [==============================] - 122s 885ms/step - loss: 3.0944 - accuracy: 0.2358 - val_loss: 3.6619 - val_accuracy: 0.2020\n",
      "Epoch 182/250\n",
      "138/138 [==============================] - 122s 882ms/step - loss: 3.0770 - accuracy: 0.2364 - val_loss: 3.4565 - val_accuracy: 0.1985\n",
      "Epoch 183/250\n",
      "138/138 [==============================] - 122s 885ms/step - loss: 3.1000 - accuracy: 0.2358 - val_loss: 3.7097 - val_accuracy: 0.1946\n",
      "Epoch 184/250\n",
      "138/138 [==============================] - 136s 987ms/step - loss: 3.0966 - accuracy: 0.2353 - val_loss: 3.6399 - val_accuracy: 0.2008\n",
      "Epoch 185/250\n",
      "138/138 [==============================] - 140s 1s/step - loss: 3.0772 - accuracy: 0.2364 - val_loss: 3.4456 - val_accuracy: 0.2145\n",
      "Epoch 186/250\n",
      "138/138 [==============================] - 142s 1s/step - loss: 3.0908 - accuracy: 0.2354 - val_loss: 3.4146 - val_accuracy: 0.2004\n",
      "Epoch 187/250\n",
      "138/138 [==============================] - 139s 1s/step - loss: 3.0793 - accuracy: 0.2389 - val_loss: 3.7871 - val_accuracy: 0.1939\n",
      "Epoch 188/250\n",
      "138/138 [==============================] - 141s 1s/step - loss: 3.0771 - accuracy: 0.2409 - val_loss: 3.5478 - val_accuracy: 0.2115\n",
      "Epoch 189/250\n",
      "138/138 [==============================] - 139s 1s/step - loss: 3.0838 - accuracy: 0.2371 - val_loss: 3.6660 - val_accuracy: 0.2022\n",
      "Epoch 190/250\n",
      "138/138 [==============================] - 137s 993ms/step - loss: 3.0878 - accuracy: 0.2370 - val_loss: 3.4468 - val_accuracy: 0.2068\n",
      "Epoch 191/250\n",
      "138/138 [==============================] - 142s 1s/step - loss: 3.0682 - accuracy: 0.2392 - val_loss: 3.5641 - val_accuracy: 0.1999\n",
      "Epoch 192/250\n",
      "138/138 [==============================] - 149s 1s/step - loss: 3.0725 - accuracy: 0.2379 - val_loss: 3.7112 - val_accuracy: 0.1874\n",
      "Epoch 193/250\n",
      "138/138 [==============================] - 136s 986ms/step - loss: 3.0907 - accuracy: 0.2385 - val_loss: 3.2715 - val_accuracy: 0.1939\n",
      "Epoch 194/250\n",
      "138/138 [==============================] - 154s 1s/step - loss: 3.0761 - accuracy: 0.2391 - val_loss: 3.7926 - val_accuracy: 0.1969\n",
      "Epoch 195/250\n",
      "138/138 [==============================] - 136s 984ms/step - loss: 3.0704 - accuracy: 0.2365 - val_loss: 3.6009 - val_accuracy: 0.2115\n",
      "Epoch 196/250\n",
      "138/138 [==============================] - 134s 972ms/step - loss: 3.0574 - accuracy: 0.2428 - val_loss: 3.4089 - val_accuracy: 0.2196\n",
      "Epoch 197/250\n",
      "138/138 [==============================] - 134s 969ms/step - loss: 3.0527 - accuracy: 0.2414 - val_loss: 3.9713 - val_accuracy: 0.1988\n",
      "Epoch 198/250\n",
      "138/138 [==============================] - 137s 991ms/step - loss: 3.0688 - accuracy: 0.2381 - val_loss: 3.6122 - val_accuracy: 0.1950\n",
      "Epoch 199/250\n",
      "138/138 [==============================] - 131s 946ms/step - loss: 3.0615 - accuracy: 0.2437 - val_loss: 3.3867 - val_accuracy: 0.2173\n",
      "Epoch 200/250\n",
      "138/138 [==============================] - 138s 997ms/step - loss: 3.0595 - accuracy: 0.2420 - val_loss: 3.6492 - val_accuracy: 0.2050\n",
      "Epoch 201/250\n",
      "138/138 [==============================] - 129s 932ms/step - loss: 3.0579 - accuracy: 0.2397 - val_loss: 3.6717 - val_accuracy: 0.2154\n",
      "Epoch 202/250\n",
      "138/138 [==============================] - 130s 945ms/step - loss: 3.0494 - accuracy: 0.2428 - val_loss: 3.3457 - val_accuracy: 0.1948\n",
      "Epoch 203/250\n",
      "138/138 [==============================] - 130s 945ms/step - loss: 3.0469 - accuracy: 0.2403 - val_loss: 3.4163 - val_accuracy: 0.2034\n",
      "Epoch 204/250\n",
      "138/138 [==============================] - 125s 907ms/step - loss: 3.0772 - accuracy: 0.2379 - val_loss: 3.4178 - val_accuracy: 0.1994\n",
      "Epoch 205/250\n",
      "138/138 [==============================] - 120s 870ms/step - loss: 3.0590 - accuracy: 0.2446 - val_loss: 3.8069 - val_accuracy: 0.2004\n",
      "Epoch 206/250\n",
      "138/138 [==============================] - 122s 885ms/step - loss: 3.0549 - accuracy: 0.2410 - val_loss: 3.5432 - val_accuracy: 0.1964\n",
      "Epoch 207/250\n",
      "138/138 [==============================] - 124s 898ms/step - loss: 3.0485 - accuracy: 0.2445 - val_loss: 3.7071 - val_accuracy: 0.1946\n",
      "Epoch 208/250\n",
      "138/138 [==============================] - 128s 927ms/step - loss: 3.0342 - accuracy: 0.2450 - val_loss: 3.6036 - val_accuracy: 0.2071\n",
      "Epoch 209/250\n",
      "138/138 [==============================] - 131s 946ms/step - loss: 3.0415 - accuracy: 0.2428 - val_loss: 3.3568 - val_accuracy: 0.2173\n",
      "Epoch 210/250\n",
      "138/138 [==============================] - 2664s 19s/step - loss: 3.0385 - accuracy: 0.2425 - val_loss: 3.5412 - val_accuracy: 0.2147\n",
      "Epoch 211/250\n",
      "138/138 [==============================] - 120s 871ms/step - loss: 3.0653 - accuracy: 0.2373 - val_loss: 3.0427 - val_accuracy: 0.1997\n",
      "Epoch 212/250\n",
      "138/138 [==============================] - 113s 817ms/step - loss: 3.0454 - accuracy: 0.2438 - val_loss: 3.5309 - val_accuracy: 0.1983\n",
      "Epoch 213/250\n",
      "138/138 [==============================] - 114s 825ms/step - loss: 3.0305 - accuracy: 0.2440 - val_loss: 3.4448 - val_accuracy: 0.2029\n",
      "Epoch 214/250\n",
      "138/138 [==============================] - 114s 823ms/step - loss: 3.0246 - accuracy: 0.2462 - val_loss: 3.2997 - val_accuracy: 0.2034\n",
      "Epoch 215/250\n",
      "138/138 [==============================] - 113s 819ms/step - loss: 3.0454 - accuracy: 0.2411 - val_loss: 3.3798 - val_accuracy: 0.2038\n",
      "Epoch 216/250\n",
      "138/138 [==============================] - 113s 817ms/step - loss: 3.0463 - accuracy: 0.2425 - val_loss: 3.6192 - val_accuracy: 0.2022\n",
      "Epoch 217/250\n",
      "138/138 [==============================] - 113s 821ms/step - loss: 3.0179 - accuracy: 0.2479 - val_loss: 3.7669 - val_accuracy: 0.2050\n",
      "Epoch 218/250\n",
      "138/138 [==============================] - 115s 836ms/step - loss: 3.0399 - accuracy: 0.2421 - val_loss: 4.2401 - val_accuracy: 0.2045\n",
      "Epoch 219/250\n",
      "138/138 [==============================] - 118s 856ms/step - loss: 3.0299 - accuracy: 0.2463 - val_loss: 3.3856 - val_accuracy: 0.2018\n",
      "Epoch 220/250\n",
      "138/138 [==============================] - 121s 877ms/step - loss: 3.0253 - accuracy: 0.2462 - val_loss: 3.6910 - val_accuracy: 0.2161\n",
      "Epoch 221/250\n",
      "138/138 [==============================] - 129s 936ms/step - loss: 3.0297 - accuracy: 0.2473 - val_loss: 3.1457 - val_accuracy: 0.2177\n",
      "Epoch 222/250\n",
      "138/138 [==============================] - 136s 985ms/step - loss: 3.0423 - accuracy: 0.2456 - val_loss: 3.2651 - val_accuracy: 0.2110\n",
      "Epoch 223/250\n",
      "138/138 [==============================] - 157s 1s/step - loss: 3.0188 - accuracy: 0.2472 - val_loss: 3.4281 - val_accuracy: 0.1997\n",
      "Epoch 224/250\n",
      "138/138 [==============================] - 144s 1s/step - loss: 3.0179 - accuracy: 0.2513 - val_loss: 3.8959 - val_accuracy: 0.1851\n",
      "Epoch 225/250\n",
      "138/138 [==============================] - 141s 1s/step - loss: 3.0159 - accuracy: 0.2496 - val_loss: 2.9397 - val_accuracy: 0.2145\n",
      "Epoch 226/250\n",
      "138/138 [==============================] - 141s 1s/step - loss: 3.0302 - accuracy: 0.2433 - val_loss: 3.5918 - val_accuracy: 0.2108\n",
      "Epoch 227/250\n",
      "138/138 [==============================] - 133s 967ms/step - loss: 3.0240 - accuracy: 0.2486 - val_loss: 3.3912 - val_accuracy: 0.2101\n",
      "Epoch 228/250\n",
      "138/138 [==============================] - 138s 1s/step - loss: 3.0128 - accuracy: 0.2508 - val_loss: 3.1809 - val_accuracy: 0.2052\n",
      "Epoch 229/250\n",
      "138/138 [==============================] - 136s 986ms/step - loss: 3.0170 - accuracy: 0.2512 - val_loss: 3.5298 - val_accuracy: 0.1932\n",
      "Epoch 230/250\n",
      "138/138 [==============================] - 133s 966ms/step - loss: 3.0022 - accuracy: 0.2495 - val_loss: 3.4112 - val_accuracy: 0.2145\n",
      "Epoch 231/250\n",
      "138/138 [==============================] - 150s 1s/step - loss: 3.0328 - accuracy: 0.2490 - val_loss: 3.3981 - val_accuracy: 0.1960\n",
      "Epoch 232/250\n",
      "138/138 [==============================] - 136s 989ms/step - loss: 3.0153 - accuracy: 0.2477 - val_loss: 3.4831 - val_accuracy: 0.2059\n",
      "Epoch 233/250\n",
      "138/138 [==============================] - 141s 1s/step - loss: 3.0091 - accuracy: 0.2516 - val_loss: 3.6252 - val_accuracy: 0.2050\n",
      "Epoch 234/250\n",
      "138/138 [==============================] - 147s 1s/step - loss: 3.0107 - accuracy: 0.2506 - val_loss: 3.8256 - val_accuracy: 0.2122\n",
      "Epoch 235/250\n",
      "138/138 [==============================] - 141s 1s/step - loss: 3.0159 - accuracy: 0.2498 - val_loss: 3.5020 - val_accuracy: 0.2115\n",
      "Epoch 236/250\n",
      "138/138 [==============================] - 130s 940ms/step - loss: 2.9988 - accuracy: 0.2505 - val_loss: 3.3567 - val_accuracy: 0.2089\n",
      "Epoch 237/250\n",
      "138/138 [==============================] - 139s 1s/step - loss: 3.0040 - accuracy: 0.2510 - val_loss: 3.4347 - val_accuracy: 0.2207\n",
      "Epoch 238/250\n",
      "138/138 [==============================] - 171s 1s/step - loss: 3.0042 - accuracy: 0.2501 - val_loss: 3.5249 - val_accuracy: 0.1955\n",
      "Epoch 239/250\n",
      "138/138 [==============================] - 174s 1s/step - loss: 3.0034 - accuracy: 0.2512 - val_loss: 3.6588 - val_accuracy: 0.2015\n",
      "Epoch 240/250\n",
      "138/138 [==============================] - 144s 1s/step - loss: 3.0101 - accuracy: 0.2515 - val_loss: 3.7548 - val_accuracy: 0.2048\n",
      "Epoch 241/250\n",
      "138/138 [==============================] - 142s 1s/step - loss: 3.0096 - accuracy: 0.2450 - val_loss: 3.7581 - val_accuracy: 0.1985\n",
      "Epoch 242/250\n",
      "138/138 [==============================] - 144s 1s/step - loss: 3.0052 - accuracy: 0.2503 - val_loss: 3.1144 - val_accuracy: 0.2048\n",
      "Epoch 243/250\n",
      "138/138 [==============================] - 132s 956ms/step - loss: 2.9972 - accuracy: 0.2515 - val_loss: 3.4067 - val_accuracy: 0.2022\n",
      "Epoch 244/250\n",
      "138/138 [==============================] - 135s 975ms/step - loss: 3.0001 - accuracy: 0.2510 - val_loss: 3.2116 - val_accuracy: 0.2004\n",
      "Epoch 245/250\n",
      "138/138 [==============================] - 130s 942ms/step - loss: 2.9984 - accuracy: 0.2515 - val_loss: 3.7144 - val_accuracy: 0.1886\n",
      "Epoch 246/250\n",
      "138/138 [==============================] - 133s 964ms/step - loss: 2.9944 - accuracy: 0.2546 - val_loss: 3.3551 - val_accuracy: 0.2096\n",
      "Epoch 247/250\n",
      "138/138 [==============================] - 141s 1s/step - loss: 2.9938 - accuracy: 0.2547 - val_loss: 3.4571 - val_accuracy: 0.2149\n",
      "Epoch 248/250\n",
      "138/138 [==============================] - 146s 1s/step - loss: 2.9953 - accuracy: 0.2489 - val_loss: 3.5743 - val_accuracy: 0.2004\n",
      "Epoch 249/250\n",
      "138/138 [==============================] - 156s 1s/step - loss: 2.9848 - accuracy: 0.2552 - val_loss: 3.6009 - val_accuracy: 0.2020\n",
      "Epoch 250/250\n",
      "138/138 [==============================] - 150s 1s/step - loss: 2.9927 - accuracy: 0.2542 - val_loss: 3.5050 - val_accuracy: 0.2131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23f1ac88488>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = None,\n",
    "                         epochs = 250,\n",
    "                         validation_data = test_set,    \n",
    "                         validation_steps = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "otterhound\n"
     ]
    }
   ],
   "source": [
    "# Part 3 - Making new predictions\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img(r\"C:\\Users\\kriti\\OneDrive\\Pictures\\otter.jpg\", target_size = (64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "print(result)\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'Chihuahua'\n",
    "    print(prediction)\n",
    "elif result[0][1] == 1:\n",
    "    prediction = 'Japanese_spaniel'\n",
    "    print(prediction)\n",
    "elif result[0][2] == 1:\n",
    "    prediction = 'Maltese_dog'\n",
    "    print(prediction)\n",
    "elif result[0][3] == 1:\n",
    "    prediction = 'Pekinese'\n",
    "    print(prediction)\n",
    "elif result[0][4] == 1:\n",
    "    prediction = 'Shih-Tzu'\n",
    "    print(prediction)\n",
    "elif result[0][5] == 1:\n",
    "    prediction = 'Blenheim_spaniel'\n",
    "    print(prediction)\n",
    "elif result[0][6] == 1:\n",
    "    prediction = 'papillon'\n",
    "    print(prediction)\n",
    "elif result[0][7] == 1:\n",
    "    prediction = 'toy_terrier'\n",
    "    print(prediction)\n",
    "elif result[0][8] == 1:\n",
    "    prediction = 'Rhodesian_ridgeback'\n",
    "    print(prediction)\n",
    "elif result[0][9] == 1:\n",
    "    prediction = 'Afghan_hound'\n",
    "    print(prediction)\n",
    "elif result[0][10] == 1:\n",
    "    prediction = 'basset'\n",
    "    print(prediction)\n",
    "elif result[0][11] == 1:\n",
    "    prediction = 'beagle'\n",
    "    print(prediction)\n",
    "elif result[0][12] == 1:\n",
    "    prediction = 'bloodhound'\n",
    "    print(prediction)\n",
    "elif result[0][13] == 1:\n",
    "    prediction = 'bluetick'\n",
    "    print(prediction)\n",
    "elif result[0][14] == 1:\n",
    "    prediction = 'black-and-tan_coonhound'\n",
    "    print(prediction)\n",
    "elif result[0][15] == 1:\n",
    "    prediction = 'Walker_hound'\n",
    "    print(prediction)\n",
    "elif result[0][16] == 1:\n",
    "    prediction = 'English_foxhound'\n",
    "    print(prediction)\n",
    "elif result[0][17] == 1:\n",
    "    prediction = 'redbone'\n",
    "    print(prediction)\n",
    "elif result[0][18] == 1:\n",
    "    prediction = 'borzoi'\n",
    "    print(prediction)\n",
    "elif result[0][19] == 1:\n",
    "    prediction = 'Irish_wolfhound'\n",
    "    print(prediction)\n",
    "elif result[0][20] == 1:\n",
    "    prediction = 'Italian_greyhound'\n",
    "    print(prediction)\n",
    "elif result[0][21] == 1:\n",
    "    prediction = 'whippet'\n",
    "    print(prediction)\n",
    "elif result[0][22] == 1:\n",
    "    prediction = 'Ibizan_hound'\n",
    "    print(prediction)\n",
    "elif result[0][23] == 1:\n",
    "    prediction = 'Norwegian_elkhound'\n",
    "    print(prediction)\n",
    "elif result[0][24] == 1:\n",
    "    prediction = 'otterhound'\n",
    "    print(prediction)\n",
    "elif result[0][25] == 1:\n",
    "    prediction = 'Saluki'\n",
    "    print(prediction)\n",
    "elif result[0][26] == 1:\n",
    "    prediction = 'Scottish_deerhound'\n",
    "    print(prediction)\n",
    "elif result[0][27] == 1:\n",
    "    prediction = 'Weimaraner'\n",
    "    print(prediction)\n",
    "elif result[0][28] == 1:\n",
    "    prediction = 'Staffordshire_bullterrier'\n",
    "    print(prediction)\n",
    "elif result[0][29] == 1:\n",
    "    prediction = 'American_Staffordshire_terrier'\n",
    "    print(prediction)\n",
    "elif result[0][30] == 1:\n",
    "    prediction = 'Bedlington_terrier'\n",
    "    print(prediction)\n",
    "elif result[0][31] == 1:\n",
    "    prediction = 'Border_terrier'\n",
    "    print(prediction)\n",
    "elif result[0][32] == 1:\n",
    "    prediction = 'Kerry_blue_terrier'\n",
    "    print(prediction)\n",
    "elif result[0][33] == 1:\n",
    "    prediction = 'Irish_terrier'\n",
    "    print(prediction)\n",
    "elif result[0][34] == 1:\n",
    "    prediction = 'Norfolk_terrier'\n",
    "    print(prediction)\n",
    "elif result[0][35] == 1:\n",
    "    prediction = 'Norwich_terrier'\n",
    "    print(prediction)\n",
    "elif result[0][36] == 1:\n",
    "    prediction = 'Yorkshire_terrier'\n",
    "    print(prediction)\n",
    "elif result[0][37] == 1:\n",
    "    prediction = 'wire-haired_fox_terrier'\n",
    "    print(prediction)\n",
    "elif result[0][38] == 1:\n",
    "    prediction = 'Lakeland_terrier'\n",
    "    print(prediction)\n",
    "elif result[0][39] == 1:\n",
    "    prediction = 'Sealyham_terrier'\n",
    "    print(prediction)\n",
    "elif result[0][40] == 1:\n",
    "    prediction = 'Airedale'\n",
    "    print(prediction)\n",
    "elif result[0][41] == 1:\n",
    "    prediction = 'cairn'\n",
    "    print(prediction)\n",
    "elif result[0][42] == 1:\n",
    "    prediction = 'Australian_terrier'\n",
    "    print(prediction)\n",
    "elif result[0][43] == 1:\n",
    "    prediction = 'Dandie_Dinmont'\n",
    "    print(prediction)\n",
    "elif result[0][44] == 1:\n",
    "    prediction = 'Boston_bull'\n",
    "    print(prediction)\n",
    "elif result[0][45] == 1:\n",
    "    prediction = 'miniature_schnauzer'\n",
    "    print(prediction)\n",
    "elif result[0][46] == 1:\n",
    "    prediction = 'giant_schnauzer'\n",
    "    print(prediction)\n",
    "elif result[0][47] == 1:\n",
    "    prediction = 'standard_schnauzer'\n",
    "    print(prediction)\n",
    "elif result[0][48] == 1:\n",
    "    prediction = 'Scotch_terrier'\n",
    "    print(prediction)\n",
    "elif result[0][49] == 1:\n",
    "    prediction = 'Tibetan_terrier'\n",
    "    print(prediction)\n",
    "elif result[0][50] == 1:\n",
    "    prediction = 'silky_terrier'\n",
    "    print(prediction)\n",
    "elif result[0][51] == 1:\n",
    "    prediction = 'soft-coated_wheaten_terrier'\n",
    "    print(prediction)\n",
    "elif result[0][52] == 1:\n",
    "    prediction = 'West_Highland_white_terrier'\n",
    "    print(prediction)\n",
    "elif result[0][53] == 1:\n",
    "    prediction = 'Lhasa'\n",
    "    print(prediction)\n",
    "elif result[0][54] == 1:\n",
    "    prediction = 'flat-coated_retriever'\n",
    "    print(prediction)\n",
    "elif result[0][55] == 1:\n",
    "    prediction = 'curly-coated_retriever'\n",
    "    print(prediction)\n",
    "elif result[0][56] == 1:\n",
    "    prediction = 'golden_retriever'\n",
    "    print(prediction)\n",
    "elif result[0][57] == 1:\n",
    "    prediction = 'Labrador_retriever'\n",
    "    print(prediction)\n",
    "elif result[0][58] == 1:\n",
    "    prediction = 'Chesapeake_Bay_retriever'\n",
    "    print(prediction)\n",
    "elif result[0][59] == 1:\n",
    "    prediction = 'German_short-haired_pointer'\n",
    "    print(prediction)\n",
    "elif result[0][60] == 1:\n",
    "    prediction = 'vizsla'\n",
    "    print(prediction)\n",
    "elif result[0][61] == 1:\n",
    "    prediction = 'English_setter'\n",
    "    print(prediction)\n",
    "elif result[0][62] == 1:\n",
    "    prediction = 'Irish_setter'\n",
    "    print(prediction)\n",
    "elif result[0][63] == 1:\n",
    "    prediction = 'Gordon_setter'\n",
    "    print(prediction)\n",
    "elif result[0][64] == 1:\n",
    "    prediction = 'Brittany_spaniel'\n",
    "    print(prediction)\n",
    "elif result[0][65] == 1:\n",
    "    prediction = 'clumber'\n",
    "    print(prediction)\n",
    "elif result[0][66] == 1:\n",
    "    prediction = 'English_springer'\n",
    "    print(prediction)\n",
    "elif result[0][67] == 1:\n",
    "    prediction = 'Welsh_springer_spaniel'\n",
    "    print(prediction)\n",
    "elif result[0][68] == 1:\n",
    "    prediction = 'cocker_spaniel'\n",
    "    print(prediction)\n",
    "elif result[0][69] == 1:\n",
    "    prediction = 'Sussex_spaniel'\n",
    "    print(prediction)\n",
    "elif result[0][70] == 1:\n",
    "    prediction = 'Irish_water_spaniel'\n",
    "    print(prediction)\n",
    "elif result[0][71] == 1:\n",
    "    prediction = 'kuvasz'\n",
    "    print(prediction)\n",
    "elif result[0][72] == 1:\n",
    "    prediction = 'schipperke'\n",
    "    print(prediction)\n",
    "elif result[0][73] == 1:\n",
    "    prediction = 'groenendael'\n",
    "    print(prediction)\n",
    "elif result[0][74] == 1:\n",
    "    prediction = 'malinois'\n",
    "    print(prediction)\n",
    "elif result[0][75] == 1:\n",
    "    prediction = 'briard'\n",
    "    print(prediction)\n",
    "elif result[0][76] == 1:\n",
    "    prediction = 'kelpie'\n",
    "    print(prediction)\n",
    "elif result[0][77] == 1:\n",
    "    prediction = 'komondor'\n",
    "    print(prediction)\n",
    "elif result[0][78] == 1:\n",
    "    prediction = 'Old_English_sheepdog'\n",
    "    print(prediction)\n",
    "elif result[0][79] == 1:\n",
    "    prediction = 'Shetland_sheepdog'\n",
    "    print(prediction)\n",
    "elif result[0][80] == 1:\n",
    "    prediction = 'collie'\n",
    "    print(prediction)\n",
    "elif result[0][81] == 1:\n",
    "    prediction = 'Border_collie'\n",
    "    print(prediction)\n",
    "elif result[0][82] == 1:\n",
    "    prediction = 'Bouvier_des_Flandres'\n",
    "    print(prediction)\n",
    "elif result[0][83] == 1:\n",
    "    prediction = 'Rottweiler'\n",
    "    print(prediction)\n",
    "elif result[0][84] == 1:\n",
    "    prediction = 'German_shepherd'\n",
    "    print(prediction)\n",
    "elif result[0][85] == 1:\n",
    "    prediction = 'Doberman'\n",
    "    print(prediction)\n",
    "elif result[0][86] == 1:\n",
    "    prediction = 'miniature_pinscher'\n",
    "    print(prediction)\n",
    "elif result[0][87] == 1:\n",
    "    prediction = 'Greater_Swiss_Mountain_dog'\n",
    "    print(prediction)\n",
    "elif result[0][88] == 1:\n",
    "    prediction = 'Bernese_mountain_dog'\n",
    "    print(prediction)\n",
    "elif result[0][89] == 1:\n",
    "    prediction = 'Appenzeller'\n",
    "    print(prediction)\n",
    "elif result[0][90] == 1:\n",
    "    prediction = 'EntleBucher'\n",
    "    print(prediction)\n",
    "elif result[0][91] == 1:\n",
    "    prediction = 'boxer'\n",
    "    print(prediction)\n",
    "elif result[0][92] == 1:\n",
    "    prediction = 'bull_mastiff'\n",
    "    print(prediction)\n",
    "elif result[0][93] == 1:\n",
    "    prediction = 'Tibetan_mastiff'\n",
    "    print(prediction)\n",
    "elif result[0][94] == 1:\n",
    "    prediction = 'French_bulldog'\n",
    "    print(prediction)\n",
    "elif result[0][95] == 1:\n",
    "    prediction = 'Great_Dane'\n",
    "    print(prediction)\n",
    "elif result[0][96] == 1:\n",
    "    prediction = 'Saint_Bernard'\n",
    "    print(prediction)\n",
    "elif result[0][97] == 1:\n",
    "    prediction = 'Eskimo_dog'\n",
    "    print(prediction)\n",
    "elif result[0][98] == 1:\n",
    "    prediction = 'malamute'\n",
    "    print(prediction)\n",
    "elif result[0][99] == 1:\n",
    "    prediction = 'Siberian_husky'\n",
    "    print(prediction)\n",
    "elif result[0][100] == 1:\n",
    "    prediction = 'affenpinscher'\n",
    "    print(prediction)\n",
    "elif result[0][101] == 1:\n",
    "    prediction = 'basenji'\n",
    "    print(prediction)\n",
    "elif result[0][102] == 1:\n",
    "    prediction = 'pug'\n",
    "    print(prediction)\n",
    "elif result[0][103] == 1:\n",
    "    prediction = 'Leonberg'\n",
    "    print(prediction)\n",
    "elif result[0][104] == 1:\n",
    "    prediction = 'Newfoundland'\n",
    "    print(prediction)\n",
    "elif result[0][105] == 1:\n",
    "    prediction = 'Great_Pyrenees'\n",
    "    print(prediction)\n",
    "elif result[0][106] == 1:\n",
    "    prediction = 'Samoyed'\n",
    "    print(prediction)\n",
    "elif result[0][107] == 1:\n",
    "    prediction = 'Pomeranian'\n",
    "    print(prediction)\n",
    "elif result[0][108] == 1:\n",
    "    prediction = 'chow'\n",
    "    print(prediction)\n",
    "elif result[0][109] == 1:\n",
    "    prediction = 'keeshond'\n",
    "    print(prediction)\n",
    "elif result[0][110] == 1:\n",
    "    prediction = 'Brabancon_griffon'\n",
    "    print(prediction)\n",
    "elif result[0][111] == 1:\n",
    "    prediction = 'Pembroke'\n",
    "    print(prediction)\n",
    "elif result[0][112] == 1:\n",
    "    prediction = 'Cardigan'\n",
    "    print(prediction)\n",
    "elif result[0][113] == 1:\n",
    "    prediction = 'toy_poodle'\n",
    "    print(prediction)\n",
    "elif result[0][114] == 1:\n",
    "    prediction = 'miniature_poodle'\n",
    "    print(prediction)\n",
    "elif result[0][115] == 1:\n",
    "    prediction = 'standard_poodle'\n",
    "    print(prediction)\n",
    "elif result[0][116] == 1:\n",
    "    prediction = 'Mexican_hairless'\n",
    "    print(prediction)\n",
    "elif result[0][117] == 1:\n",
    "    prediction = 'dingo'\n",
    "    print(prediction)\n",
    "elif result[0][118] == 1:\n",
    "    prediction = 'dhole'\n",
    "    print(prediction)\n",
    "else:\n",
    "    prediction = 'African_hunting_dog'\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
